{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0637c9b",
   "metadata": {},
   "source": [
    "*The following notes explore time and space complexity of algorithms and how these quantities can be measured.* \n",
    "\n",
    "Algorithms have varying complexity. This complexity becomes important as we attempt to scale and run algorithms on larger data. When we attempt to process more data with an algorithm, this will take more time and use more memory (space). Being able to quantify these changes is a useful capability. We can use this skill to estimate how an algorithm will scale, for instance linearly, exponentially, logarithmically or otherwise.\n",
    "\n",
    "There are two ways of measuring time and space complexity: empirically and theoretically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ba677",
   "metadata": {},
   "source": [
    "### Theoretically\n",
    "\n",
    "Lets begin by examining the following algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(x):\n",
    "    \"\"\"Find the maximum element in a list of positive integers.\"\"\"\n",
    "    max_ = 0\n",
    "    for el in x:\n",
    "        if el > max_:\n",
    "            max_ = el\n",
    "    return max_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a6dbf",
   "metadata": {},
   "source": [
    "To figure out the time complexity we need to go through the following steps: \n",
    "\n",
    "1. Check the variables in the program\n",
    "\n",
    "\n",
    "2. Figure out what happens when you increase these variables \n",
    "\n",
    "In the above example we only have one variable (x) which is an iterable. If we add an element to x, this will increase the number of operations our algorithm must do by 1. As this increase is linear, we would say the time-complexity is linear and represented by **O(n)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b1ca5",
   "metadata": {},
   "source": [
    "### Empirically \n",
    "\n",
    "We can empirically estimate the time-complexity of our algorithm by measuring how much time it takes to run on data that we incrementally increase in size, then we fit a curve to the results to find which rate of change best describes algorithmic complexity. Be warned though, there are some tricks to watch out for. \n",
    "\n",
    "Lets take the same example from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6edec289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max(x):\n",
    "    \"\"\"Find the maximum element in a list of positive integers.\"\"\"\n",
    "#     print(len(x))\n",
    "    max_ = 0\n",
    "    for el in x:\n",
    "        if el > max_:\n",
    "            max_ = el\n",
    "    return max_\n",
    "\n",
    "find_max([9,12,4,5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a41509",
   "metadata": {},
   "source": [
    "We can use a package like `big_O` to empirically estimate time complexity. `big_O` executes a python function for input of increasing size N, and measures its execution time. From the measurements, big_O fits a set of time complexity classes and returns the best fitting class. As specified below, we are re-running the algorithm with input arrays of increasing size (up to max of 1000 length), containing values between 0 and 100, each repeated 100 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df324ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: time = 0.00016 + 2.1E-06*n (sec)\n"
     ]
    }
   ],
   "source": [
    "import big_o\n",
    "\n",
    "# set the range of numbers that will be included within our array\n",
    "positive_int_generator = lambda n: big_o.datagen.integers(n, 0, 100)\n",
    "best, others = big_o.big_o(find_max, positive_int_generator, max_n=1000, n_repeats=100)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1ed56",
   "metadata": {},
   "source": [
    "The second return argument, **others**, contains a dictionary of all fitted classes with the residuals from the fit as keys. So the smallest residual is the best match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ecda036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: time = 0.11 (sec)                                     (res: 0.044)\n",
      "Linear: time = 0.0026 + 2.1E-06*n (sec)                         (res: 0.00017)\n",
      "Quadratic: time = 0.039 + 1.9E-11*n^2 (sec)                     (res: 0.0039)\n",
      "Cubic: time = 0.056 + 1.8E-16*n^3 (sec)                         (res: 0.0086)\n",
      "Polynomial: time = -12 * x^0.93 (sec)                           (res: 0.021)\n",
      "Logarithmic: time = -0.16 + 0.026*log(n) (sec)                  (res: 0.018)\n",
      "Linearithmic: time = 0.0077 + 1.8E-07*n*log(n) (sec)            (res: 0.0003)\n",
      "Exponential: time = -5.1 * 4.4E-05^n (sec)                      (res: 13)\n"
     ]
    }
   ],
   "source": [
    "for class_, residuals in others.items():\n",
    "    print('{!s:<60s}    (res: {:.2G})'.format(class_, residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1234f5",
   "metadata": {},
   "source": [
    "If you run this algorithm numerous times you will see you get slightly different results, because its empirical and computers are designed to optimise runtime based on initial conditions which will be subtley different each time we run the program. \n",
    "\n",
    "To accurately estimate time complexity empirically, its important to remember that `big_O` is attempting to measure for the worst case, or ceiling of growth for a given function. Therefore, you want to run your algorithm for the worst case where the algorithm takes the longest possible time to arrive at a solution. The above example will always run through the entire input so it is running worst case every time. Lets take a look at another example that does not do this to see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8927d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An algorithm that returns the indexes of the first two elements that equal the target when added together. \n",
    "\n",
    "def twoSum(nums, target):\n",
    "    for i, num in enumerate(nums):\n",
    "        for j in range(i+1,len(nums)):\n",
    "            if nums[i] + nums[j] == target:\n",
    "                return(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce182f",
   "metadata": {},
   "source": [
    "Lets test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092a7d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = [3,2,4]\n",
    "target = 6\n",
    "\n",
    "twoSum(nums, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d6cfd",
   "metadata": {},
   "source": [
    "Before we can empirically test this algorithm, we need to ever so slighly rewrite it to always test for the worst case scenario; that it has to traverse the entire input array `nums` completely before finding a solution. To test for this we can set the target to a number that is too large for any elements in the input array to summate to, forcing the algorithm to completely traverse the input array.\n",
    "\n",
    "Rewriting the algorithm, we can remove target as an input variable and hard code a value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fadae826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSum(nums):\n",
    "    target = 50\n",
    "    for i, num in enumerate(nums):\n",
    "        for j in range(i+1,len(nums)):\n",
    "            if nums[i] + nums[j] == target:\n",
    "                return(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61945e",
   "metadata": {},
   "source": [
    "Might take a bit more time to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a5f8ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic: time = -0.023 + 3.4E-06*n^2 (sec)\n"
     ]
    }
   ],
   "source": [
    "positive_int_generator = lambda n: big_o.datagen.integers(n, 0, 10)\n",
    "best, others = big_o.big_o(twoSum, positive_int_generator, max_n=1000, n_repeats=100)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc94b16",
   "metadata": {},
   "source": [
    "We can see this is quadratic, ie `O(n^2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1eb58e",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "- Provide explanation of how to calculate time complexity theoretically for the above case\n",
    "- Provide examples of algorithms with other time complexities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
