{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f3d016",
   "metadata": {},
   "source": [
    "*Scrape radio shows for tracklist metadata.*\n",
    "\n",
    "Online radio plays a major role in how I discover new music. I really dig how uniquely curated shows are and find myself studying tracklists, chasing down labels and trying to discern new moods and scenes from within the selections. I'd now like to explore augmenting how I discover new music through automating some of the following processes:\n",
    "\n",
    "- finding record labels that are popular sources of music within the shows I listen to \n",
    "- finding significant periods of history to mine for music\n",
    "- finding artists who perform at the same events\n",
    "\n",
    "I will begin by scraping useful metadata from a single online radio station. NTS radio is an obvious choice for me as its one of the most popular online stations, has many of my favourite regular show, has some of the metadata I need already included (record labels, tracklists) and has a website that looks reasonably straightforward to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39786e20",
   "metadata": {},
   "source": [
    "**Goal: *For a given NTS show, return a tracklist including artist, label and year recorded for each track***.\n",
    "\n",
    "For this task we'll need requests to grab the relevant HTML (our input data) and then beautifulsoup to parse the HTML so we can easily extract the text we're looking for: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbaff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5fe78",
   "metadata": {},
   "source": [
    "If we don't include headers, sites may not allow us to access their data as they will rightly think we're attempting to scrape. We can circumvent this by 'spoofing' a header to send with our request to make it seem like the request was made by a web browser.\n",
    "\n",
    "Many services will want to see a header in the request because it lets them know more about the client requesting the resource. For instance check out the header below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca5b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a747e",
   "metadata": {},
   "source": [
    "Included above is the expected user-agent header for Chrome browser. User agent is any software, acting on behalf of a user, which \"retrieves, renders and facilitates end-user interaction with Web content\". The User-Agent request header is a characteristic string that lets servers and network peers identify the application, operating system, vendor, and/or version of the requesting user agent. You might be wondering, if this is a Chrome header, why does it have Mozilla stuff in it? This is because Mozilla/5.0 is a general token that says the browser is Mozilla-compatible and most browsers (Chrome included) include this nowadays. Every browser has its own set of unique headers as seen [here]('https://www.useragentstring.com/pages/useragentstring.php'). There are all sorts of weird and wonderful browsers. Now lets attempt to grab the HTML from the following URL as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c205967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.nts.live/shows/jam-city/episodes/jam-city-17th-june-2022\"\n",
    "req = requests.get(url, headers)\n",
    "print(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b6f12",
   "metadata": {},
   "source": [
    "We got a HTTP \"200\" OK success status response code indicating that the request has succeeded. Now if we want to actually check out the HTML it recieved in response, we can call the text property on our response object where the HTML is stored as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59792b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7eb66a",
   "metadata": {},
   "source": [
    "Ok it send a bunch of text, now to parse the content of our request object with the html parser that beautifulsoup includes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ec2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cea480",
   "metadata": {},
   "source": [
    "Now we want to extract the tracklist from the HTML. Thankfully NTS haven't implemented methods that make it difficult to scrape like including dynamic classes. Instead we can quite easily describe what we're looking to extract from the HTML. \n",
    "\n",
    "- Each track's data (`track_title` and `track_artist`) are stored within span elements nested within list item elements which all sit within an unordered list `<ul>` parent element.\n",
    "\n",
    "There are a few approaches we could take to extract the data we're looking for. A straightforward approach would simply involve finding all of the list elements and then searching within those elements for the span elements and extracting their text. To get all list elements, we could simply run `soup.find_all`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407821c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = soup.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39291b3f",
   "metadata": {},
   "source": [
    "Taking a look at the first one, we can see it includes the track title, artist and even a url contained within an `href` attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e39bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li class=\"track\"><a class=\"nts-app nts-link\" data-category=\"Navigation\" data-origin=\"from: tracklist\" data-target=\"GoTo-Artist\" data-track=\"event\" href=\"/artists/9902-blue-magic\"><span class=\"track__artist\">Blue Magic</span></a><span class=\"track__artist track__artist--mobile\" style=\"display:none\">Blue Magic</span>Â <img alt=\"\" src=\"/img/go-to.svg\" style=\"height:.75em;width:.75em;position:relative;top:-.1em;margin-left:1px\"/><br/><span class=\"track__title\">Born On Halloween</span></li>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdeaf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/artists/9902-blue-magic\n"
     ]
    }
   ],
   "source": [
    "print(elements[0].find('a', href=True)['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc2a60",
   "metadata": {},
   "source": [
    "One thing to notice is that not all tracks include a url as NTS doesn't have an artist page for every artist played on air. We could take the tracklist and correlate it with other databases (maybe Discogs or Bandcamp) to get somewhere near complete metadata but that's out of scope for this exercise. To handle the lack of url for some of the items in our tracklist, we can write a `get_url` function that handles this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf794c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(element, track):\n",
    "    try:\n",
    "        return element.find('a', href=True)['href']\n",
    "    except: \n",
    "        print(\"no url for \" + track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146fff8",
   "metadata": {},
   "source": [
    "Now we can loop though all HTML within the unordered list extracting track info and saving it within a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfe7df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no url for Untitled\n",
      "no url for Ninja H2r Flyby\n",
      "no url for Only Fans (Edit)\n",
      "no url for Polyphonic Love\n",
      "no url for The Pearls (Edit)\n",
      "no url for Freaky\n",
      "no url for Unlock It (Himera Remix)\n",
      "no url for The Rain\n",
      "no url for Parties In Chelsea\n"
     ]
    }
   ],
   "source": [
    "tracklist = []\n",
    "for element in soup.find_all(\"li\"):\n",
    "    artist = element.find(\"span\",{\"class\":\"track__artist\"}).text\n",
    "    track = element.find(\"span\",{\"class\":\"track__title\"}).text\n",
    "    url = get_url(element, track)\n",
    "    if url: \n",
    "        tracklist.append({\"Artist\": artist,\n",
    "                          \"Track\" : track,\n",
    "                          \"Url\" : url})\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5da85",
   "metadata": {},
   "source": [
    "There's quite a lot of tracks missing metadata but nevermind. Here is a working tracklist for now of items we can grab more metadata from: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbfd3dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Artist': 'Blue Magic',\n",
       "  'Track': 'Born On Halloween',\n",
       "  'Url': '/artists/9902-blue-magic'},\n",
       " {'Artist': 'GQ',\n",
       "  'Track': 'Lies (Theo Parrish Re-Edit)',\n",
       "  'Url': '/artists/251-gq'},\n",
       " {'Artist': 'Otha', 'Track': \"I'm On Top\", 'Url': '/artists/79247-otha'},\n",
       " {'Artist': 'Actress',\n",
       "  'Track': 'Shadow From Tartarus',\n",
       "  'Url': '/artists/355-actress'},\n",
       " {'Artist': 'Salamandos',\n",
       "  'Track': 'Expand',\n",
       "  'Url': '/artists/118879-salamandos'},\n",
       " {'Artist': 'Chemotex',\n",
       "  'Track': 'Early Death',\n",
       "  'Url': '/artists/6521-chemotex'},\n",
       " {'Artist': 'Pev, ',\n",
       "  'Track': 'End Point (Stenny & Andrea Remix)',\n",
       "  'Url': '/artists/375-peverelist'},\n",
       " {'Artist': 'Kendrick Lamar',\n",
       "  'Track': 'United In Grief',\n",
       "  'Url': '/artists/4443-kendrick-lamar'},\n",
       " {'Artist': 'Cruel Santino',\n",
       "  'Track': 'War In The Trenches',\n",
       "  'Url': '/artists/111265-cruel-santino'},\n",
       " {'Artist': 'Machine Woman',\n",
       "  'Track': 'Camile From Ohm Makes Me Feel Loved',\n",
       "  'Url': '/artists/29327-machine-woman'},\n",
       " {'Artist': 'Reeko',\n",
       "  'Track': 'Massive Garage Meetings',\n",
       "  'Url': '/artists/21330-reeko'},\n",
       " {'Artist': 'jamesjamesjames',\n",
       "  'Track': 'My Purple iPod Nano',\n",
       "  'Url': '/artists/118880-jamesjamesjames'},\n",
       " {'Artist': 'Astrud Gilberto',\n",
       "  'Track': 'Touching You',\n",
       "  'Url': '/artists/1115-astrud-gilberto'},\n",
       " {'Artist': 'DJ Gigola, ', 'Track': 'Papi', 'Url': '/artists/85623-dj-gigola'},\n",
       " {'Artist': 'Broosnica',\n",
       "  'Track': 'Vaporizer',\n",
       "  'Url': '/artists/117923-broosnica'},\n",
       " {'Artist': 'Section 25',\n",
       "  'Track': 'Be Brave',\n",
       "  'Url': '/artists/4215-section-25'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0f7fb",
   "metadata": {},
   "source": [
    "Now we want to get the record label for each artist in the tracklist. The record label metadata can be found at the Url for each track. However at some of the Url's this metadata will initially be hidden from us as NTS limits the number of tracks displayed for an artist's page. In this instance we'll have to click the 'MORE TRACKS' button with Selenium to load the full HTML before we can attempt scraping the metadata.\n",
    "\n",
    "For ease lets solve for the easier use-case where we don't need Selenium and the metadata can be scraped from the HTML loaded at the Url. \"Born on Halloween\" by the band Blue Magic is a track we can test extracting metadata from as it loads without Javascript in the HTML. First we need to grab the HTML for the artist page which we extracted in the previous code, parse the HTML and then search for the element containing the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea3c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nts.live/artists/9902-blue-magic'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.nts.live\" + tracklist[0]['Url']\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3680f",
   "metadata": {},
   "source": [
    "Get the HTML for Blue Magic's artist page: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f63293",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url, headers)\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3a11be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"artist-track__name text-bold text-uppercase\">Born On Halloween</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track = soup.find(\"div\", string=tracklist[0]['Track'])\n",
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8315a",
   "metadata": {},
   "source": [
    "Now we have the div, we want to get the metadata within the parent div: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0790538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"artist-track__meta__item\">Blue Magic</span>,\n",
       " <span class=\"artist-track__meta__item\">ATCO Records</span>,\n",
       " <span class=\"artist-track__meta__item\">â¢</span>,\n",
       " <span class=\"artist-track__meta__item\">1975</span>,\n",
       " <span class=\"artist-track__link-icon icon icon-link-arrow\"></span>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = track.parent.find_all(\"span\")\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176030d",
   "metadata": {},
   "source": [
    "Metadata format is standard for all tracks so we know we can pull the record label from the same index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18178b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATCO Records'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31d9fa",
   "metadata": {},
   "source": [
    "Lets write a function which takes a url as input and outputs the record label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06af9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(url, track):\n",
    "    url = \"https://www.nts.live\" + url\n",
    "    req = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    track = soup.find(\"div\", string=track)\n",
    "    if track:\n",
    "        label = track.parent.find_all(\"span\")[1].text\n",
    "        return label\n",
    "    else: \n",
    "        print(\"need Selenium\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e061b3",
   "metadata": {},
   "source": [
    "Works for the examples where we can pull the metadata from the HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16246832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ugly Edits'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = get_label(tracklist[1]['Url'],tracklist[1]['Track'])\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e2731",
   "metadata": {},
   "source": [
    "But not so for examples where we need the Javascript to load the metadata: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6677f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need Selenium\n"
     ]
    }
   ],
   "source": [
    "label = get_label(tracklist[3]['Url'],tracklist[3]['Track'])\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce55be7",
   "metadata": {},
   "source": [
    "Lets now solve for the case where we need selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "882eff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88269fd9",
   "metadata": {},
   "source": [
    "Test url: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fda246",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.nts.live/artists/355-actress\")\n",
    "soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85320a6",
   "metadata": {},
   "source": [
    "Now we want to click the 'MORE TRACKS' button:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c39683c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_elements(By.CLASS_NAME, \"artist-section__view-handler\")\n",
    "elem[1].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe94cb6",
   "metadata": {},
   "source": [
    "Although we actually want to keep on clicking another other 'MORE TRACKS' buttons until the full HTML loads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d768913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while driver.find_element(\"xpath\", \"//*[contains(text(), 'MORE TRACKS')]\"):\n",
    "    try: \n",
    "        element = driver.find_element(\"xpath\", \"//*[contains(text(), 'MORE TRACKS')]\")\n",
    "        element.click()\n",
    "    except: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009e4ce",
   "metadata": {},
   "source": [
    "Full HTML after clicking: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f7da7",
   "metadata": {},
   "source": [
    "Great! We can see the HTML includes the tracks that were previously hidden, now we can adjust our original function to account for the examples where selenium is required: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ea07701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_webpage(url, track): \n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service(executable_path=ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(url)\n",
    "    soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    while driver.find_element(\"xpath\", \"//*[contains(text(), 'MORE TRACKS')]\"):\n",
    "        try: \n",
    "            element = driver.find_element(\"xpath\", \"//*[contains(text(), 'MORE TRACKS')]\")\n",
    "            element.click()\n",
    "        except: \n",
    "            break\n",
    "    soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    track_info = soup.find(\"div\", string=track)\n",
    "    if track_info:\n",
    "        label = track_info.parent.find_all(\"span\")[1].text\n",
    "        return label\n",
    "\n",
    "def get_label(url, track):\n",
    "    url = \"https://www.nts.live\" + url\n",
    "    req = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    track_info = soup.find(\"div\", string=track)\n",
    "    if track_info:\n",
    "        label = track_info.parent.find_all(\"span\")[1].text\n",
    "        return label\n",
    "    else: \n",
    "        label = get_full_webpage(url, track)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d823bf0a",
   "metadata": {},
   "source": [
    "Now we can test and see if it grabs the label for Actress' Shadow From Tartarus which was previously hidden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63bfdc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Honest Jon's Records\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = get_label(tracklist[3]['Url'],tracklist[3]['Track'])\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1704f46",
   "metadata": {},
   "source": [
    "We can now loop through the tracklist and find the rest of the labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2dae8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Magic - Born On Halloween [ATCO Records]\n",
      "GQ - Lies (Theo Parrish Re-Edit) [Ugly Edits]\n",
      "Otha - I'm On Top [Not On Label (Otha (2) Self-released)]\n",
      "Actress - Shadow From Tartarus [Honest Jon's Records]\n",
      "Salamandos - Expand [CrÃ¨me Organization]\n",
      "Chemotex - Early Death [The Trilogy Tapes]\n",
      "Pev,  - End Point (Stenny & Andrea Remix) [Livity Sound]\n",
      "Kendrick Lamar - United In Grief [pgLang, Top Dawg Entertainment, Aftermath/Interscope Records]\n",
      "Cruel Santino - War In The Trenches [Monster Boy, Interscope Records]\n",
      "Machine Woman - Camile From Ohm Makes Me Feel Loved [Technicolour]\n",
      "Reeko - Massive Garage Meetings [Avian]\n",
      "jamesjamesjames - My Purple iPod Nano [Shall Not Fade]\n",
      "Astrud Gilberto - Touching You [Perception Records]\n",
      "DJ Gigola,  - Papi [Live From Earth Klub]\n",
      "Broosnica - Vaporizer [Hyperboloid]\n",
      "Section 25 - Be Brave [Factory]\n"
     ]
    }
   ],
   "source": [
    "for track in tracklist: \n",
    "    label = get_label(track['Url'],track['Track'])\n",
    "    print(track['Artist'] + \" - \" + track['Track'] + \" [\" + label + \"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
